{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1233d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba07cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a5a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = range(0,35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6edaa98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1        2        3        4        5        6        7        8   \\\n",
       "0   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "1   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "2   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "3   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "4   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "        9   ...       25       26       27       28       29       30  \\\n",
       "0  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "1 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "2  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "3  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "4 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "        31       32       33  34  \n",
       "0 -0.54487  0.18641 -0.45300   g  \n",
       "1 -0.06288 -0.13738 -0.02447   b  \n",
       "2 -0.24180  0.56045 -0.38238   g  \n",
       "3  1.00000 -0.32382  1.00000   b  \n",
       "4 -0.59573 -0.04608 -0.65697   g  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/ionosphere/ionosphere.data\",names=names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bcdb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.0</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "      <td>351.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.891738</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641342</td>\n",
       "      <td>0.044372</td>\n",
       "      <td>0.601068</td>\n",
       "      <td>0.115889</td>\n",
       "      <td>0.550095</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.511848</td>\n",
       "      <td>0.181345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>-0.071187</td>\n",
       "      <td>0.541641</td>\n",
       "      <td>-0.069538</td>\n",
       "      <td>0.378445</td>\n",
       "      <td>-0.027907</td>\n",
       "      <td>0.352514</td>\n",
       "      <td>-0.003794</td>\n",
       "      <td>0.349364</td>\n",
       "      <td>0.014480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.311155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.497708</td>\n",
       "      <td>0.441435</td>\n",
       "      <td>0.519862</td>\n",
       "      <td>0.460810</td>\n",
       "      <td>0.492654</td>\n",
       "      <td>0.520750</td>\n",
       "      <td>0.507066</td>\n",
       "      <td>0.483851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578451</td>\n",
       "      <td>0.508495</td>\n",
       "      <td>0.516205</td>\n",
       "      <td>0.550025</td>\n",
       "      <td>0.575886</td>\n",
       "      <td>0.507974</td>\n",
       "      <td>0.571483</td>\n",
       "      <td>0.513574</td>\n",
       "      <td>0.522663</td>\n",
       "      <td>0.468337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>-0.064735</td>\n",
       "      <td>0.412660</td>\n",
       "      <td>-0.024795</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>-0.054840</td>\n",
       "      <td>0.087110</td>\n",
       "      <td>-0.048075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.332390</td>\n",
       "      <td>0.286435</td>\n",
       "      <td>-0.443165</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.236885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.242595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.165350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.871110</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.809200</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.728730</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.684210</td>\n",
       "      <td>0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553890</td>\n",
       "      <td>-0.015050</td>\n",
       "      <td>0.708240</td>\n",
       "      <td>-0.017690</td>\n",
       "      <td>0.496640</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334655</td>\n",
       "      <td>0.969240</td>\n",
       "      <td>0.445675</td>\n",
       "      <td>0.953240</td>\n",
       "      <td>0.534195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.905240</td>\n",
       "      <td>0.156765</td>\n",
       "      <td>0.999945</td>\n",
       "      <td>0.153535</td>\n",
       "      <td>0.883465</td>\n",
       "      <td>0.154075</td>\n",
       "      <td>0.857620</td>\n",
       "      <td>0.200120</td>\n",
       "      <td>0.813765</td>\n",
       "      <td>0.171660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0      1           2           3           4           5   \\\n",
       "count  351.000000  351.0  351.000000  351.000000  351.000000  351.000000   \n",
       "mean     0.891738    0.0    0.641342    0.044372    0.601068    0.115889   \n",
       "std      0.311155    0.0    0.497708    0.441435    0.519862    0.460810   \n",
       "min      0.000000    0.0   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%      1.000000    0.0    0.472135   -0.064735    0.412660   -0.024795   \n",
       "50%      1.000000    0.0    0.871110    0.016310    0.809200    0.022800   \n",
       "75%      1.000000    0.0    1.000000    0.194185    1.000000    0.334655   \n",
       "max      1.000000    0.0    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               6           7           8           9   ...          24  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  ...  351.000000   \n",
       "mean     0.550095    0.119360    0.511848    0.181345  ...    0.396135   \n",
       "std      0.492654    0.520750    0.507066    0.483851  ...    0.578451   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000  ...   -1.000000   \n",
       "25%      0.211310   -0.054840    0.087110   -0.048075  ...    0.000000   \n",
       "50%      0.728730    0.014710    0.684210    0.018290  ...    0.553890   \n",
       "75%      0.969240    0.445675    0.953240    0.534195  ...    0.905240   \n",
       "max      1.000000    1.000000    1.000000    1.000000  ...    1.000000   \n",
       "\n",
       "               25          26          27          28          29          30  \\\n",
       "count  351.000000  351.000000  351.000000  351.000000  351.000000  351.000000   \n",
       "mean    -0.071187    0.541641   -0.069538    0.378445   -0.027907    0.352514   \n",
       "std      0.508495    0.516205    0.550025    0.575886    0.507974    0.571483   \n",
       "min     -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   -1.000000   \n",
       "25%     -0.332390    0.286435   -0.443165    0.000000   -0.236885    0.000000   \n",
       "50%     -0.015050    0.708240   -0.017690    0.496640    0.000000    0.442770   \n",
       "75%      0.156765    0.999945    0.153535    0.883465    0.154075    0.857620   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "               31          32          33  \n",
       "count  351.000000  351.000000  351.000000  \n",
       "mean    -0.003794    0.349364    0.014480  \n",
       "std      0.513574    0.522663    0.468337  \n",
       "min     -1.000000   -1.000000   -1.000000  \n",
       "25%     -0.242595    0.000000   -0.165350  \n",
       "50%      0.000000    0.409560    0.000000  \n",
       "75%      0.200120    0.813765    0.171660  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bd0693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.34843328  0.          0.71237237 ... -1.05505394 -0.3122206\n",
      "  -0.99959483]\n",
      " [ 0.34843328  0.          0.72164805 ... -0.11521328 -0.93260505\n",
      "  -0.08328554]\n",
      " [ 0.34843328  0.          0.72164805 ... -0.46409249  0.40444328\n",
      "  -0.84859079]\n",
      " ...\n",
      " [ 0.34843328  0.          0.61502805 ...  0.01601615  1.10669878\n",
      "  -0.04330004]\n",
      " [ 0.34843328  0.          0.53267371 ... -0.06586087  1.00526528\n",
      "  -0.37828012]\n",
      " [ 0.34843328  0.          0.41400137 ... -0.12281796  0.9738619\n",
      "  -0.16248675]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "train_data = data.drop([34],axis=1)\n",
    "train_label = data[34]\n",
    "scaler = StandardScaler()\n",
    "model=scaler.fit(train_data)\n",
    "Impute_data=model.transform(train_data)\n",
    "\n",
    "# print scaled features\n",
    "print(Impute_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21955b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'g': 225, 'b': 126})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(np.array(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb9c8cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.where(train_label=='g',0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ad3303",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = Impute_data\n",
    "y = train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf41622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TLCM 0.3253968253968254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from src.measures import tlcm, degIR, degOver, imbalance_ratio, n_1_imb_mean, n_3_imb_mean\n",
    "\n",
    "dataset = Bunch(data=np.array(X),target=np.array(y))\n",
    "TLCM = tlcm(dataset)\n",
    "print(\"TLCM\",TLCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f237760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(train_data,train_label,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a52c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 194 22 31\n"
     ]
    }
   ],
   "source": [
    "print(sum(y_train==1)\n",
    ",sum(y_train==0)\n",
    ",sum(y_test==1)\n",
    ",sum(y_test==0)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6aedeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sum(y_train==1)+sum(y_test==1))/(sum(y_train==0)+sum(y_test==0))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a642fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = x_train\n",
    "train_label = y_train\n",
    "test_data = x_test\n",
    "test_label=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d85ae013",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_weights(indices, y_train, k):\n",
    "    class_0 = []\n",
    "    class_1 = []\n",
    "    data = pd.DataFrame(indices)\n",
    "    data = data.set_index(data.columns[0])\n",
    "    for i in data.index:\n",
    "        dict1 = {}\n",
    "        for j in data.iloc[i]:\n",
    "            dict1[y_train[j]] = dict1.get(y_train[j], 0) + 1\n",
    "        class_0.append(dict1.get(0, 0))\n",
    "        class_1.append(dict1.get(1, 0))\n",
    "    data[\"class_0\"] = class_0\n",
    "    data[\"class_1\"] = class_1\n",
    "    data[\"Class\"] = y_train\n",
    "    data[\"cost\"] = np.where(\n",
    "        data[\"Class\"] == 0,\n",
    "        ((data[\"class_1\"] + 1) / k) * sum(data[\"Class\"] == 1),\n",
    "        ((data[\"class_0\"] + 1) / k) * sum(data[\"Class\"] == 0),\n",
    "    )\n",
    "    return data[\"cost\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e4448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8867924528301887\n",
      "Precision score 0.8421052631578948\n",
      "Recall score 0.7272727272727273\n",
      "F1 score 1.0\n",
      "Kappa score 0.7572519083969466\n",
      "Gmean weighted score 0.9153348228041135\n",
      "Roc auc score 0.8636363636363636\n",
      "Precision -Recall score 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42)\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3d2502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8867924528301887\n",
      "Precision score 0.8571428571428572\n",
      "Recall score 0.8181818181818182\n",
      "F1 score 0.9\n",
      "Kappa score 0.763744427934621\n",
      "Gmean weighted score 0.8893306982833162\n",
      "Roc auc score 0.8768328445747802\n",
      "Precision -Recall score 0.7740994854202402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42,class_weight={0:sum(np.array(train_label)==1),1:sum(np.array(train_label)==0)})\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5704213d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8867924528301887\n",
      "Precision score 0.8421052631578948\n",
      "Recall score 0.7272727272727273\n",
      "F1 score 1.0\n",
      "Kappa score 0.7572519083969466\n",
      "Gmean weighted score 0.9153348228041135\n",
      "Roc auc score 0.8636363636363636\n",
      "Precision -Recall score 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42,class_weight=\"balanced\")\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d0586d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8490566037735849\n",
      "Precision score 0.8181818181818182\n",
      "Recall score 0.8181818181818182\n",
      "F1 score 0.8181818181818182\n",
      "Kappa score 0.6891495601173021\n",
      "Gmean weighted score 0.8441622892989753\n",
      "Roc auc score 0.844574780058651\n",
      "Precision -Recall score 0.7448931857165134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42)\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel(),AdaWeight(train_data,train_label,k=5))\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02347275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaWeight(x_train, y_train, k):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(x_train)\n",
    "    dist, indices = nbrs.kneighbors(x_train)\n",
    "    return cost_weights(indices, y_train, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f0eb0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c593290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import Bunch\n",
    "from src.measures import tlcm, degIR, degOver, imbalance_ratio, n_1_imb_mean, n_3_imb_mean\n",
    "\n",
    "dataset = Bunch(data=np.array(X),target=np.array(y))\n",
    "TLCM = tlcm(dataset)\n",
    "IR   = imbalance_ratio(dataset)\n",
    "N1   = n_1_imb_mean(dataset)\n",
    "N3   = n_3_imb_mean(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3b046f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_class_weight(measure,value):\n",
    "    C_W = {}\n",
    "    if measure==\"IR\":\n",
    "        C_W[0] = round((1/value)*100,2)\n",
    "        C_W[1] = 100\n",
    "    else:\n",
    "        C_W[0] = round(value*100,2)\n",
    "        C_W[1] = 100\n",
    "    return C_W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35e50d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8867924528301887\n",
      "Precision score 0.8571428571428572\n",
      "Recall score 0.8181818181818182\n",
      "F1 score 0.9\n",
      "Kappa score 0.763744427934621\n",
      "Gmean weighted score 0.8893306982833162\n",
      "Roc auc score 0.8768328445747802\n",
      "Precision -Recall score 0.7740994854202402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42,class_weight=cal_class_weight('IR',imbalance_ratio(dataset)))\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de7f57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8867924528301887\n",
      "Precision score 0.8571428571428572\n",
      "Recall score 0.8181818181818182\n",
      "F1 score 0.9\n",
      "Kappa score 0.763744427934621\n",
      "Gmean weighted score 0.8893306982833162\n",
      "Roc auc score 0.8768328445747802\n",
      "Precision -Recall score 0.7740994854202402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42,class_weight=cal_class_weight('TLCM',tlcm(dataset)))\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b73fee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8679245283018868\n",
      "Precision score 0.8292682926829269\n",
      "Recall score 0.7727272727272727\n",
      "F1 score 0.8947368421052632\n",
      "Kappa score 0.7225130890052356\n",
      "Gmean weighted score 0.873589088036728\n",
      "Roc auc score 0.8541055718475073\n",
      "Precision -Recall score 0.7291234088652162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42,class_weight=cal_class_weight('N1',n_1_imb_mean(dataset)))\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63df91c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8679245283018868\n",
      "Precision score 0.8292682926829269\n",
      "Recall score 0.7727272727272727\n",
      "F1 score 0.8947368421052632\n",
      "Kappa score 0.7225130890052356\n",
      "Gmean weighted score 0.873589088036728\n",
      "Roc auc score 0.8541055718475073\n",
      "Precision -Recall score 0.7291234088652162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score,average_precision_score\n",
    "lr_imb=LogisticRegression(random_state=42,class_weight=cal_class_weight('N3',n_3_imb_mean(dataset)))\n",
    "lr_imb_model=lr_imb.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=lr_imb_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(test_label,pred_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470abf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
