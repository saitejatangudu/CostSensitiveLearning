{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5757de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import roc_auc_score,average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54bf52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"abalone_test_data.csv\")\n",
    "test_label = pd.read_csv(\"abalone_test_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = np.ravel(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87e8ab5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>F</th>\n",
       "      <th>I</th>\n",
       "      <th>M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.408339</td>\n",
       "      <td>0.343271</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0.310881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.467709</td>\n",
       "      <td>0.316770</td>\n",
       "      <td>0.507331</td>\n",
       "      <td>0.284974</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>0.307501</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.385142</td>\n",
       "      <td>0.186528</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.505376</td>\n",
       "      <td>0.513158</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.212327</td>\n",
       "      <td>0.181781</td>\n",
       "      <td>0.172043</td>\n",
       "      <td>0.132642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.128484</td>\n",
       "      <td>0.087785</td>\n",
       "      <td>0.125122</td>\n",
       "      <td>0.109326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Length  Diameter    Height  whole weight  Shucked weight  Viscera weight  \\\n",
       "0  0.741935  0.763158  0.622222      0.408339        0.343271        0.322581   \n",
       "1  0.763441  0.802632  0.622222      0.467709        0.316770        0.507331   \n",
       "2  0.698925  0.697368  0.577778      0.307501        0.276190        0.385142   \n",
       "3  0.505376  0.513158  0.488889      0.212327        0.181781        0.172043   \n",
       "4  0.397849  0.434211  0.444444      0.128484        0.087785        0.125122   \n",
       "\n",
       "   Shell weight    F    I    M  \n",
       "0      0.310881  0.0  0.0  1.0  \n",
       "1      0.284974  0.0  0.0  1.0  \n",
       "2      0.186528  0.0  1.0  0.0  \n",
       "3      0.132642  0.0  1.0  0.0  \n",
       "4      0.109326  0.0  1.0  0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5685557e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"abalone_train_data.csv\")\n",
    "train_label = pd.read_csv(\"abalone_train_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2debd97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9272727272727272\n",
      "F1 score: 0.5\n",
      "Precision score: 0.4\n",
      "Recall score: 0.6666666666666666\n",
      "Kappa score: 0.46341463414634154\n",
      "Gmean weighted score: 0.792593923901217\n",
      "Roc auc score: 0.8044871794871794\n",
      "Precision-Recall score: 0.28484848484848485\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state =42,class_weight={0:sum(np.array(train_label)==1),1:sum(np.array(train_label)==0)})\n",
    "dtree_model=dtree.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=dtree_model.predict(test_data)\n",
    "print(f\"Accuracy score: {accuracy_score(test_label, pred_label)}\")\n",
    "print(f\"F1 score: {f1_score(test_label, pred_label)}\")\n",
    "print(f\"Precision score: {precision_score(test_label, pred_label)}\")\n",
    "print(f\"Recall score: {recall_score(test_label, pred_label)}\")\n",
    "print(f\"Kappa score: {cohen_kappa_score(test_label, pred_label)}\")\n",
    "print(f\"Gmean weighted score: {geometric_mean_score(test_label, pred_label)}\")\n",
    "print(f\"Roc auc score: {roc_auc_score(test_label, pred_label)}\")\n",
    "print(f\"Precision-Recall score: {average_precision_score(test_label, pred_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "295b2424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.9090909090909091\n",
      "F1 score: 0.37499999999999994\n",
      "Precision score: 0.3\n",
      "Recall score: 0.5\n",
      "Kappa score: 0.3292682926829269\n",
      "Gmean weighted score: 0.6828954194063348\n",
      "Roc auc score: 0.716346153846154\n",
      "Precision-Recall score: 0.17727272727272728\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state =42)\n",
    "dtree_model=dtree.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=dtree_model.predict(test_data)\n",
    "print(f\"Accuracy score: {accuracy_score(test_label, pred_label)}\")\n",
    "print(f\"F1 score: {f1_score(test_label, pred_label)}\")\n",
    "print(f\"Precision score: {precision_score(test_label, pred_label)}\")\n",
    "print(f\"Recall score: {recall_score(test_label, pred_label)}\")\n",
    "print(f\"Kappa score: {cohen_kappa_score(test_label, pred_label)}\")\n",
    "print(f\"Gmean weighted score: {geometric_mean_score(test_label, pred_label)}\")\n",
    "print(f\"Roc auc score: {roc_auc_score(test_label, pred_label)}\")\n",
    "print(f\"Precision-Recall score: {average_precision_score(test_label, pred_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab8c991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((621, 10), (110, 10), (621, 1), (110, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape,test_data.shape,train_label.shape,test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "096c6a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'pca_init'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ec431f02b254>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Perform t-SNE with 2 components (for 2D visualization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtsne\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpca_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtsne_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtsne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'pca_init'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Concatenate train_data and test_data for t-SNE visualization\n",
    "combined_data = np.vstack((train_data, test_data))\n",
    "combined_labels = np.concatenate((train_label, test_label)).ravel()\n",
    "\n",
    "# Perform t-SNE with 2 components (for 2D visualization)\n",
    "tsne = TSNE(n_components=2, random_state=42, learning_rate='auto', pca_init=1e-4)\n",
    "tsne_result = tsne.fit_transform(combined_data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Scatter plot for each class\n",
    "for label in np.unique(combined_labels):\n",
    "    indices = combined_labels == label\n",
    "    plt.scatter(tsne_result[indices, 0], tsne_result[indices, 1], label=f'Class {label}')\n",
    "\n",
    "plt.title('t-SNE Visualization')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f496a1a",
   "metadata": {},
   "source": [
    "### 05:95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40e6bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"abalone_ext_imb_data.csv\")\n",
    "train_label = pd.read_csv(\"abalone_ext_imb_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2bddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.9090909090909091\n",
      "Precision score 0.37499999999999994\n",
      "Recall score 0.5\n",
      "F1 score 0.3\n",
      "Kappa score 0.3292682926829269\n",
      "Gmean weighted score 0.539444158370447\n",
      "Roc auc score 0.6349999999999999\n",
      "Precision -Recall score 0.21363636363636362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state =42,class_weight={0:sum(np.array(train_label)==1),1:sum(np.array(train_label)==0)})\n",
    "dtree_model=dtree.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=dtree_model.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(pred_label,test_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d7ec46",
   "metadata": {},
   "source": [
    "### 15:85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3927893",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"abalone_15285_imb_data.csv\")\n",
    "train_label = pd.read_csv(\"abalone_15285_imb_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c168eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8818181818181818\n",
      "Precision score 0.3157894736842105\n",
      "Recall score 0.5\n",
      "F1 score 0.23076923076923078\n",
      "Kappa score 0.26059979317476734\n",
      "Gmean weighted score 0.4728974921323095\n",
      "Roc auc score 0.5999206978588422\n",
      "Precision -Recall score 0.2062937062937063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree1 = DecisionTreeClassifier(random_state =42,class_weight={0:sum(np.array(train_label)==1),1:sum(np.array(train_label)==0)})\n",
    "dtree_model1=dtree1.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=dtree_model1.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(pred_label,test_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944b732",
   "metadata": {},
   "source": [
    "### 30:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77cd6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"abalone_mod_imb_data.csv\")\n",
    "train_label = pd.read_csv(\"abalone_mod_imb_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b234ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8818181818181818\n",
      "Precision score 0.3809523809523809\n",
      "Recall score 0.6666666666666666\n",
      "F1 score 0.26666666666666666\n",
      "Kappa score 0.32863849765258213\n",
      "Gmean weighted score 0.510933098926804\n",
      "Roc auc score 0.6228070175438597\n",
      "Precision -Recall score 0.2777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree2= DecisionTreeClassifier(random_state =42,class_weight={0:sum(np.array(train_label)==1),1:sum(np.array(train_label)==0)})\n",
    "dtree_model2=dtree2.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=dtree_model2.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(pred_label,test_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e869d54f",
   "metadata": {},
   "source": [
    "### 50:50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ba7ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"abalone_no_imb_data.csv\")\n",
    "train_label = pd.read_csv(\"abalone_no_imb_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f92b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8545454545454545\n",
      "Precision score 0.3846153846153846\n",
      "Recall score 0.8333333333333334\n",
      "F1 score 0.25\n",
      "Kappa score 0.3282442748091604\n",
      "Gmean weighted score 0.49721446300587663\n",
      "Roc auc score 0.6194444444444445\n",
      "Precision -Recall score 0.3446969696969697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/Utilities/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score,cohen_kappa_score\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree3 = DecisionTreeClassifier(random_state =42,class_weight={0:sum(np.array(train_label)==1),1:sum(np.array(train_label)==0)})\n",
    "dtree_model3=dtree3.fit(train_data,np.array(train_label).ravel())\n",
    "pred_label=dtree_model3.predict(test_data)\n",
    "print(f\"Accuracy score %s\"%accuracy_score(pred_label,test_label))\n",
    "print(f\"Precision score %s\"%f1_score(pred_label,test_label))\n",
    "print(f\"Recall score %s\"%precision_score(pred_label,test_label))\n",
    "print(f\"F1 score %s\"%recall_score(pred_label,test_label))\n",
    "print(f\"Kappa score %s\"%cohen_kappa_score(pred_label,test_label))\n",
    "print(f\"Gmean weighted score %s\"%geometric_mean_score(pred_label, test_label))\n",
    "print(f\"Roc auc score %s\"%roc_auc_score(pred_label,test_label))\n",
    "print(f\"Precision -Recall score %s\"%average_precision_score(pred_label,test_label))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
